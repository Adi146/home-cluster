---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: whisper
  labels:
    app: whisper
spec:
  strategy: 
    type: Recreate
  replicas: 1
  selector:
    matchLabels:
      app: whisper
  template:
    metadata:
      labels:
        app: whisper
    spec:
      containers:
        - name: whisper
          image: rhasspy/wyoming-whisper:2.4.0
          volumeMounts:
          - name: whisper-volume
            mountPath: /data
          command:
            - bash
            - -c
            - |
              pip install nvidia-cublas-cu12 nvidia-cudnn-cu12==8.9.2.26 && \
              export LD_LIBRARY_PATH=$(python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))') && \
              /run.sh --model large-v3 --language de --device cuda
          resources:
            limits:
              nvidia.com/gpu: "1"
          ports:
            - name: voice
              containerPort: 10300
              protocol: TCP
      volumes:
        - name: whisper-volume
          persistentVolumeClaim:
            claimName: whisper-pvc
